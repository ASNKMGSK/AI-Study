{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 가위바위보 분류기 만들기\n",
    "먼저 데이터를 직접 준비하기 위해, 구글의 [teachable machine](https://teachablemachine.withgoogle.com/)사이트에 접속을 해서 카메라로 자신의 손모양(가위, 바위, 보)를 찍어서 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-81e6cb6bf7d2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-81e6cb6bf7d2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mkdir -p ~/aiffel/rock_scissor_paper/scissor\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 폴더를 3개 만들고 그 안에 가위는 가위끼리 바위는 바위끼리 저장한다.\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "# ls -l로 잘 만들어졌는지 확인해보자\n",
    "ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/ssac3/anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 자 이제 본격적으로 데이터를 정제하기 전에 몇가지 작업이 필요하다.\n",
    "# pip명령어로 pillow라이브러리를 설치하고 그 안에 있는 image를 import시킨다\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽는다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 위의 가위 이미지를 읽어들이는 코드와 마찬가지로, 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들인다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 똑같이, 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들인다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6900 입니다.\n",
      "x_train shape: (6900, 28, 28, 3)\n",
      "y_train shape: (6900,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\nx_train, x_test, y_train, y_test = train_test_split(x_train_norm, y_train, test_size=0.3, shuffle=True, stratify=y_train, random_state=222)\\nprint(x.shape, y.shape)\\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 만들어본다.\n",
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=6900   # 가위바위보 데이터 총합을 뜻한다\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "#주석 처리해 놓은 부분은 트레인 데이터와 테스트 데이터를 분할하면서 골고루 섞어주는 코드인데 여기서는 쓰지 않겠다.\n",
    "'''from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_norm, y_train, test_size=0.3, shuffle=True, stratify=y_train, random_state=222)\n",
    "print(x.shape, y.shape)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib 안에 있는 함수를 사용하여 데이터를 정제한뒤의 이미지를 한번 살펴보자\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[2])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 24)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        6944      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                38448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 147       \n",
      "=================================================================\n",
      "Total params: 46,211\n",
      "Trainable params: 46,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 네트워크를 설계하기 위해서 tensorflow와 numpy 라이브러리를 추가하고 진행한다\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 값을 변경할 수 있는 하이퍼파라미터들을 여기 모아두었다\n",
    "n_channel_1=24\n",
    "n_channel_2=32\n",
    "n_dense=48\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9935\n",
      "Epoch 2/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9957\n",
      "Epoch 3/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9975\n",
      "Epoch 4/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9972\n",
      "Epoch 5/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9829\n",
      "Epoch 6/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9948\n",
      "Epoch 7/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 8/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9988\n",
      "Epoch 9/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9958\n",
      "Epoch 10/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9996\n",
      "Epoch 11/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e740a4ed0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 훈련시켜보자\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련을 시켰으면 제대로 훈련이 됐는지 테스트를 해야할 것이다. 일단 그 전에 테스트 데이터셋을 만들어주자(훈련 데이터셋을 만들것과 동일한 방식으로 만들어준다)\n",
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합을 넣어줘야한다.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성한다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 274.8966 - accuracy: 0.7100\n",
      "test_loss: 274.8966064453125 \n",
      "test_accuracy: 0.7099999785423279\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 테스트 데이트셋을 만들었으니, 이것으로 테스트를 해보고 모델의 정확도를 확인해본다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "처음에는 훈련 데이터셋을 가위,바위,보 각각 100개씩 해서 총 300개로 하고 학습을 시켰더니, 정확도가 0.3~0.4로 낮았다. 그러나 다른 팀원의 데이터셋을 추가한 결과 정확도가 높아졌다. 결국, 정확도가 처음에 낮게 나왔다는 것은 학습 데이터에 지나치게 과적합 되었다라고 보면 되는데, 이것을 해결하기 위해서는 데이터셋의 개수를 늘리기, 모델의 복잡도 줄이기, 드롭아웃, 가중치 규제 등의 방법이 있다. 그 유명한 MNIST의 손글씨 트레이닝 셋이 60000개고 내 데이터셋은 고작 6900에 불과하니 대략 9배 차이나 나는 것이다. 물론 정확도를 높이기 위한 방법은 위에서 나열한 방법말고도 훈련 데이터셋에서 정확하지 않은(가위인데 가위같이 생기지 않았거나) 데이터셋을 제거하거나, 이미지의 픽셀(여기서는 28x28로 크기를 줄였다)을 원본 화질 그대로 사용해서 질 좋은 데이터셋을 사용하는 방법도 있지만 여기서는 쓰지 않았다. 정리하자면, 이번 프로젝트에서는 데이터셋의 중요성과 전처리에서부터 학습까지의 프로세스를 대략적으로 학습해보는 계기가 되었다고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
