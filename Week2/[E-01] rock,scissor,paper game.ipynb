{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 가위바위보 분류기 만들기\n",
    "먼저 데이터를 직접 준비하기 위해, 구글의 [teachable machine](https://teachablemachine.withgoogle.com/)사이트에 접속을 해서 카메라로 자신의 손모양(가위, 바위, 보)를 찍어서 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더를 3개 만들고 그 안에 가위는 가위끼리 바위는 바위끼리 저장한다.\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "# ls -l로 잘 만들어졌는지 확인해보자\n",
    "ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/ssac3/anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 자 이제 본격적으로 데이터를 정제하기 전에 몇가지 작업이 필요하다.\n",
    "# pip명령어로 pillow라이브러리를 설치하고 그 안에 있는 image를 import시킨다\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽는다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 위의 가위 이미지를 읽어들이는 코드와 마찬가지로, 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들인다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac3/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 똑같이, 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들인다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장한다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6900 입니다.\n",
      "x_train shape: (6900, 28, 28, 3)\n",
      "y_train shape: (6900,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\nx_train, x_test, y_train, y_test = train_test_split(x_train_norm, y_train, test_size=0.3, shuffle=True, stratify=y_train, random_state=222)\\nprint(x.shape, y.shape)\\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 만들어본다.\n",
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=6900   # 가위바위보 데이터 총합을 뜻한다\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "#주석 처리해 놓은 부분은 트레인 데이터와 테스트 데이터를 분할하면서 골고루 섞어주는 코드인데 여기서는 쓰지 않겠다.\n",
    "'''from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_norm, y_train, test_size=0.3, shuffle=True, stratify=y_train, random_state=222)\n",
    "print(x.shape, y.shape)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib 안에 있는 함수를 사용하여 데이터를 정제한뒤의 이미지를 한번 살펴보자\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[2])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 24)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        6944      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                38448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 147       \n",
      "=================================================================\n",
      "Total params: 46,211\n",
      "Trainable params: 46,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 네트워크를 설계하기 위해서 tensorflow와 numpy 라이브러리를 추가하고 진행한다\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 값을 변경할 수 있는 하이퍼파라미터들을 여기 모아두었다\n",
    "n_channel_1=24\n",
    "n_channel_2=32\n",
    "n_dense=48\n",
    "n_train_epoch=25\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.0009 - accuracy: 0.4896\n",
      "Epoch 2/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.7313\n",
      "Epoch 3/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8341\n",
      "Epoch 4/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8955\n",
      "Epoch 5/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9297\n",
      "Epoch 6/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9500\n",
      "Epoch 7/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9661\n",
      "Epoch 8/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9678\n",
      "Epoch 9/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9803\n",
      "Epoch 10/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9862\n",
      "Epoch 11/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9910\n",
      "Epoch 12/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9886\n",
      "Epoch 13/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9904\n",
      "Epoch 14/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9943\n",
      "Epoch 15/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9954\n",
      "Epoch 16/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9964\n",
      "Epoch 17/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9804\n",
      "Epoch 18/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9961\n",
      "Epoch 19/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      "Epoch 20/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9981\n",
      "Epoch 21/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 22/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9997\n",
      "Epoch 23/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b6c0cfe50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 훈련시켜보자\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련을 시켰으면 제대로 훈련이 됐는지 테스트를 해야할 것이다. 일단 그 전에 테스트 데이터셋을 만들어주자(훈련 데이터셋을 만들것과 동일한 방식으로 만들어준다)\n",
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합을 넣어줘야한다.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성한다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 255.4072 - accuracy: 0.7267\n",
      "test_loss: 255.40716552734375 \n",
      "test_accuracy: 0.7266666889190674\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 테스트 데이트셋을 만들었으니, 이것으로 테스트를 해보고 모델의 정확도를 확인해본다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "처음에는 훈련 데이터셋을 가위,바위,보 각각 100개씩 해서 총 300개로 하고 학습을 시켰더니, 정확도가 0.3~0.4로 낮았다. 그러나 다른 팀원의 데이터셋을 추가한 결과 정확도가 높아졌다. 결국, 정확도가 처음에 낮게 나왔다는 것은 학습 데이터에 지나치게 과적합 되었다라고 보면 되는데, 이것을 해결하기 위해서는 데이터셋의 개수를 늘리기, 모델의 복잡도 줄이기, 드롭아웃, 가중치 규제 등의 방법이 있다. 그 유명한 MNIST의 손글씨 트레이닝 셋이 60000개고 내 데이터셋은 고작 6900에 불과하니 대략 9배 차이나 나는 것이다. 물론 정확도를 높이기 위한 방법은 위에서 나열한 방법말고도 훈련 데이터셋에서 정확하지 않은(가위인데 가위같이 생기지 않았거나) 데이터셋을 제거하거나, 이미지의 픽셀(여기서는 28x28로 크기를 줄였다)을 원본 화질 그대로 사용해서 질 좋은 데이터셋을 사용하는 방법도 있지만 여기서는 쓰지 않았다. 정리하자면, 이번 프로젝트에서는 데이터셋의 중요성과 전처리에서부터 학습까지의 프로세스를 대략적으로 학습해보는 계기가 되었다고 생각한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
